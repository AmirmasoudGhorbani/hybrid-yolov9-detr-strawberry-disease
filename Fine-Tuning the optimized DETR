import torch
import torchvision
import os
import pytorch_lightning as pl
from torch.utils.data import DataLoader
from transformers import DetrImageProcessor, DetrForObjectDetection
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import random
import cv2
import numpy as np

# Define paths to your dataset
train_path = '/content/drive/MyDrive/dataset/dataset json format/train'
val_path = '/content/drive/MyDrive/dataset/dataset json format/valid'
annotation_file = '_annotations.coco.json'

# Setup DetrImageProcessor
processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")

# Custom CocoDetection class for your dataset
class CocoDetection(torchvision.datasets.CocoDetection):
    def __init__(self, img_folder, processor, train=True):
        ann_file = os.path.join(img_folder, annotation_file)
        super(CocoDetection, self).__init__(img_folder, ann_file)
        self.processor = processor

    def __getitem__(self, idx):
        img, target = super(CocoDetection, self).__getitem__(idx)
        image_id = self.ids[idx]
        target = {'image_id': image_id, 'annotations': target}
        encoding = self.processor(images=img, annotations=target, return_tensors="pt")
        pixel_values = encoding["pixel_values"].squeeze()
        target = encoding["labels"][0]
        return pixel_values, target

# Create training and validation datasets
train_dataset = CocoDetection(img_folder=train_path, processor=processor)
val_dataset = CocoDetection(img_folder=val_path, processor=processor, train=False)

# Check dataset information
print(f"Number of training images: {len(train_dataset)}")
print(f"Number of validation images: {len(val_dataset)}")

# DataLoader with custom collate function
def collate_fn(batch):
    pixel_values = [item[0] for item in batch]
    encoding = processor.pad(pixel_values, return_tensors="pt")
    labels = [item[1] for item in batch]
    batch = {}
    batch['pixel_values'] = encoding['pixel_values']
    batch['pixel_mask'] = encoding['pixel_mask']
    batch['labels'] = labels
    return batch

train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=4, shuffle=True, num_workers=11)  # Adjusted batch size and num_workers for better GPU utilization
val_dataloader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=4, num_workers=11)

# Define the PyTorch Lightning model
class Detr(pl.LightningModule):
    def __init__(self, lr, lr_backbone, weight_decay):
        super().__init__()
        self.model = DetrForObjectDetection.from_pretrained("/content/drive/MyDrive/detr_strawberry_model_finetuned",
                                                            num_labels=13,  # 12 classes + 1 for 'no object'
                                                            ignore_mismatched_sizes=True)
        self.lr = lr
        self.lr_backbone = lr_backbone
        self.weight_decay = weight_decay

    def forward(self, pixel_values, pixel_mask):
        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)
        return outputs

    def common_step(self, batch, batch_idx):
        pixel_values = batch["pixel_values"]
        pixel_mask = batch["pixel_mask"]
        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch["labels"]]
        for label in labels:
            label["class_labels"] = torch.clamp(label["class_labels"], min=0, max=self.model.config.num_labels - 2)
        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)
        loss = outputs.loss
        loss_dict = outputs.loss_dict
        return loss, loss_dict

    def training_step(self, batch, batch_idx):
        loss, loss_dict = self.common_step(batch, batch_idx)
        self.log("training_loss", loss, prog_bar=True)
        for k, v in loss_dict.items():
            self.log("train_" + k, v.item(), prog_bar=True)
        return loss

    def validation_step(self, batch, batch_idx):
        loss, loss_dict = self.common_step(batch, batch_idx)
        self.log("validation_loss", loss, prog_bar=True)
        for k, v in loss_dict.items():
            self.log("validation_" + k, v.item(), prog_bar=True)
        return loss

    def configure_optimizers(self):
        param_dicts = [
            {"params": [p for n, p in self.named_parameters() if "backbone" not in n and p.requires_grad]},
            {"params": [p for n, p in self.named_parameters() if "backbone" in n and p.requires_grad],
             "lr": self.lr_backbone},
        ]
        optimizer = torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)
        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # StepLR scheduler
        return [optimizer], [lr_scheduler]

# Fine-tune the model using PyTorch Lightning
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
torch.set_float32_matmul_precision('medium')
os.environ['TORCH_USE_CUDA_DSA'] = '1'  # Enable CUDA device-side assertions for debugging
model = Detr(lr=1e-5, lr_backbone=1e-6, weight_decay=1e-4)  # Lower learning rates for fine-tuning
trainer = pl.Trainer(max_epochs=50, devices=1, accelerator='gpu', log_every_n_steps=10, enable_progress_bar=True)
trainer.fit(model, train_dataloader, val_dataloader)

# Save the fine-tuned model
model.model.save_pretrained("/content/drive/MyDrive/detr_strawberry_model_extrafinetuned")
processor.save_pretrained("/content/drive/MyDrive/detr_strawberry_processor_extrafinetuned")

# Inference and Visualization
def plot_results(pil_img, scores, labels, boxes):
    plt.figure(figsize=(16, 10))
    plt.imshow(pil_img)
    ax = plt.gca()
    colors = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098]] * 100
    for score, label, (xmin, ymin, xmax, ymax), c in zip(scores.tolist(), labels.tolist(), boxes.tolist(), colors):
        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=c, linewidth=3))
        text = f'{model.model.config.id2label[label]}: {score:0.2f}'
        ax.text(xmin, ymin, text, fontsize=15, bbox=dict(facecolor='yellow', alpha=0.5))
    plt.axis('off')
    plt.show()

# Load an image from the validation set and visualize predictions
image_id = val_dataset.coco.getImgIds()[0]
image = val_dataset.coco.loadImgs(image_id)[0]
image = Image.open(os.path.join(val_path, image['file_name']))

# Run inference
pixel_values, _ = val_dataset[0]
pixel_values = pixel_values.unsqueeze(0).to(model.device)
with torch.no_grad():
    outputs = model.model(pixel_values=pixel_values)

# Post-process the outputs
width, height = image.size
results = processor.post_process_object_detection(outputs, target_sizes=[(height, width)], threshold=0.9)[0]
plot_results(image, results['scores'], results['labels'], results['boxes'])

# Visualize if dataset is loaded properly
# Select a random image from the training dataset and visualize
image_ids = train_dataset.coco.getImgIds()
image_id = random.choice(image_ids)
print(f"Image #{image_id}")

# Load image and annotations
image = train_dataset.coco.loadImgs(image_id)[0]
annotations = train_dataset.coco.imgToAnns[image_id]
image_path = os.path.join(train_dataset.root, image['file_name'])
image = cv2.imread(image_path)

# Annotate ground truth
categories = train_dataset.coco.cats
id2label = {k: v['name'] for k, v in categories.items()}
detections = []
labels = [
    f"{id2label[ann['category_id']]}"
    for ann in annotations
]

# Display the annotated image
plt.figure(figsize=(10, 10))
for ann in annotations:
    bbox = ann['bbox']
    x, y, w, h = bbox
    cv2.rectangle(image, (int(x), int(y)), (int(x + w), int(y + h)), (255, 0, 0), 2)
    cv2.putText(image, id2label[ann['category_id']], (int(x), int(y - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)

plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.show()

# Analysis of the model's performance
def analyze_model_performance(trainer):
    # Access the training and validation metrics logged during training
    training_loss = trainer.callback_metrics.get('training_loss', None)
    validation_loss = trainer.callback_metrics.get('validation_loss', None)
    if training_loss is not None and validation_loss is not None:
        print(f"Final Training Loss: {training_loss:.4f}")
        print(f"Final Validation Loss: {validation_loss:.4f}")
    else:
        print("Metrics not found. Ensure the model has been properly trained.")

# Perform analysis after model training is complete
analyze_model_performance(trainer)

# Generate and visualize a confusion matrix after loading the saved model
def plot_confusion_matrix(model_path, val_dataloader):
    model = DetrForObjectDetection.from_pretrained(model_path)
    model.eval()
    model.to('cuda' if torch.cuda.is_available() else 'cpu')

    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for batch in val_dataloader:
            pixel_values = batch["pixel_values"].to(model.device)
            labels = [t['class_labels'].tolist() for t in batch["labels"]]
            outputs = model(pixel_values=pixel_values)
            preds = torch.argmax(outputs.logits, dim=-1).tolist()
            all_preds.extend(preds)
            all_labels.extend(labels)

    cm = confusion_matrix(all_labels, all_preds, labels=list(range(model.config.num_labels)))
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(model.config.id2label.values()))
    disp.plot()
    plt.show()

# Plot confusion matrix for the fine-tuned model
plot_confusion_matrix("/content/drive/MyDrive/detr_strawberry_model_extrafinetuned", val_dataloader)
